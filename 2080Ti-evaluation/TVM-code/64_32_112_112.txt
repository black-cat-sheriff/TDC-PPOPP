ConfigSpace (len=1659571200, space_map=
   0 tile_f: Split(policy=factors, product=32, num_outputs=4) len=56
   1 tile_y: Split(policy=factors, product=112, num_outputs=4) len=140
   2 tile_x: Split(policy=factors, product=112, num_outputs=4) len=140
   3 tile_rc: Split(policy=factors, product=64, num_outputs=3) len=28
   4 tile_ry: Split(policy=factors, product=3, num_outputs=3) len=3
   5 tile_rx: Split(policy=factors, product=3, num_outputs=3) len=3
   6 auto_unroll_max_step: OtherOption([0, 512, 1500]) len=3
   7 unroll_explicit: OtherOption([0, 1]) len=2
)
Finish loading 150 records

Best config:
[('tile_f', [-1, 1, 2, 16]), ('tile_y', [-1, 1, 16, 1]), ('tile_x', [-1, 1, 8, 2]), ('tile_rc', [-1, 2, 1]), ('tile_ry', [-1, 1, 1]), ('tile_rx', [-1, 1, 1]), ('auto_unroll_max_step', 0), ('unroll_explicit', 0)],None,1625006
Finish loading 150 records
/home/lizhi/tvm-python/tvm/python/tvm/target/target.py:454: UserWarning: tvm.target.create() is being deprecated. Please use tvm.target.Target() instead
  warnings.warn("tvm.target.create() is being deprecated. Please use tvm.target.Target() instead")
Dump


******6*******

extern "C" __global__ void default_function_kernel0(float* __restrict__ data, float* __restrict__ kernel, float* __restrict__ compute) {
  float compute_local[32];
  __shared__ float pad_temp_shared[512];
  __shared__ float kernel_shared[64];
  float pad_temp_shared_local[2];
  float kernel_shared_local[16];
  for (int ff_c_init = 0; ff_c_init < 16; ++ff_c_init) {
    for (int xx_c_init = 0; xx_c_init < 2; ++xx_c_init) {
      compute_local[(((ff_c_init * 2) + xx_c_init))] = 0.000000e+00f;
    }
  }
  for (int rc_outer = 0; rc_outer < 32; ++rc_outer) {
    for (int ry_outer = 0; ry_outer < 3; ++ry_outer) {
      for (int rx_outer = 0; rx_outer < 3; ++rx_outer) {
        __syncthreads();
        for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner < 2; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) {
          pad_temp_shared[(((((((int)threadIdx.z) * 256) + (((int)threadIdx.y) * 16)) + (((int)threadIdx.x) * 2)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner))] = (((((1 <= (((((int)blockIdx.y) * 16) + ((int)threadIdx.y)) + ry_outer)) && ((((((int)blockIdx.y) * 16) + ((int)threadIdx.y)) + ry_outer) < 113)) && (1 <= ((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 2)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) + rx_outer))) && (((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) * 2)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) + rx_outer) < 113)) ? data[(((((((((((rc_outer * 25088) + (((int)threadIdx.z) * 12544)) + (((int)blockIdx.y) * 1792)) + (ry_outer * 112)) + (((int)threadIdx.y) * 112)) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) * 2)) + rx_outer) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) - 113))] : 0.000000e+00f);
        }
        if ((((((int)threadIdx.z) * 16) + (((int)threadIdx.x) >> 1)) + ((int)threadIdx.y)) < 32) {
          if ((((((int)threadIdx.z) * 32) + (((int)threadIdx.y) * 2)) + ((int)threadIdx.x)) < 64) {
            if (((((int)threadIdx.y) * 2) + ((int)threadIdx.x)) < 32) {
              if (((int)threadIdx.x) < 2) {
                kernel_shared[((((((int)threadIdx.z) * 32) + (((int)threadIdx.y) * 2)) + ((int)threadIdx.x)))] = kernel[(((((((((int)threadIdx.z) * 9216) + (((int)threadIdx.y) * 576)) + (rc_outer * 18)) + (((int)threadIdx.x) * 9)) + (ry_outer * 3)) + rx_outer))];
              }
            }
          }
        }
        __syncthreads();
        for (int rc_inner_outer = 0; rc_inner_outer < 2; ++rc_inner_outer) {
          for (int ax3 = 0; ax3 < 2; ++ax3) {
            pad_temp_shared_local[(ax3)] = pad_temp_shared[(((((rc_inner_outer * 256) + (((int)threadIdx.y) * 16)) + (((int)threadIdx.x) * 2)) + ax3))];
          }
          for (int ax0 = 0; ax0 < 16; ++ax0) {
            kernel_shared_local[(ax0)] = kernel_shared[((((((int)threadIdx.z) * 32) + (ax0 * 2)) + rc_inner_outer))];
          }
          for (int ff_c = 0; ff_c < 16; ++ff_c) {
            for (int xx_c = 0; xx_c < 2; ++xx_c) {
              compute_local[(((ff_c * 2) + xx_c))] = (compute_local[(((ff_c * 2) + xx_c))] + (pad_temp_shared_local[(xx_c)] * kernel_shared_local[(ff_c)]));
            }
          }
        }
      }
    }
  }
  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 16; ++ff_inner_inner_inner) {
    for (int xx_inner_inner_inner = 0; xx_inner_inner_inner < 2; ++xx_inner_inner_inner) {
      compute[((((((((((int)threadIdx.z) * 200704) + (ff_inner_inner_inner * 12544)) + (((int)blockIdx.y) * 1792)) + (((int)threadIdx.y) * 112)) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) * 2)) + xx_inner_inner_inner))] = compute_local[(((ff_inner_inner_inner * 2) + xx_inner_inner_inner))];
    }
  }
}



******6*******

Time cost of this operator: 0.000147
cnm
[src/runtime/cuda/cuda_module.cc] 
 grid=(7,7,1),  block=(8,16,2)
[src/runtime/cuda/cuda_module.cc] 
 grid=(7,7,1),  block=(8,16,2)
[src/runtime/cuda/cuda_module.cc] 
 grid=(7,7,1),  block=(8,16,2)
